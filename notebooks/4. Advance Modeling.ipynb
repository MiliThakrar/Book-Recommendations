{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7663f3-88d8-4612-ab7b-5a84bd43285a",
   "metadata": {},
   "source": [
    "# <center> Book Recommendations System - Advance Modeling</center>\n",
    "#### <center>**By: Mili Ketan Thakrar**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c83408-023d-4295-9bff-f5a6b0d5e8b7",
   "metadata": {},
   "source": [
    "<a id=\"TOC\"></a> <br>\n",
    "## Table of Contents\n",
    "1. [Introduction](#intro)\n",
    "2. [Importing Libraries and Custom Definitions](#import)\n",
    "4. [Loading the Dataset](#loading)\n",
    "5. [Data Dictionary](#dict)\n",
    "6. [Collabrative Filtering Model](#collab)\n",
    "   1. [FunkSVD](#funk)\n",
    "   2. [Evaluating Model](#eval1)\n",
    "8. [Hybrid Model (Content + Collabrative Filtering)](#hybrid)\n",
    "    1. [Evaluating Models](#eval2)\n",
    "9. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6c3a1-af93-4848-bf5f-b42b68c31187",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace597b-1a30-4bbf-ac6e-2b4bbd53eb9e",
   "metadata": {},
   "source": [
    "A book recommendation system is an intelligent application designed to help users discover books tailored to their interests and reading preferences. By analyzing user behavior, ratings, and book attributes, the system provides personalized suggestions, enhancing the reading experience and making it easier to find engaging and relevant books. This project aims to develop an efficient recommendation engine using advanced algorithms and data analysis techniques.\n",
    "\n",
    "#### **Advanced Models: Collaborative Filtering and Hybrid Approaches**\n",
    "\n",
    "In this notebook, we extend our recommendation system with advanced modeling techniques that leverage both user interactions and book content to deliver highly personalized suggestions.\n",
    "\n",
    "We will implement and evaluate the following approaches:\n",
    "\n",
    "1. **Collaborative Filtering Model**:  \n",
    "   This model predicts a user’s preferences by analyzing patterns in user ratings and interactions. By identifying similarities among users and books, collaborative filtering generates recommendations based on what similar users have enjoyed. The process includes building a machine learning pipeline, iterating on model selection, and thoroughly evaluating performance to ensure robust recommendations.\n",
    "\n",
    "2. **Hybrid Model (Content + Collaborative Filtering)**:  \n",
    "   To further enhance recommendation quality, we combine the strengths of content-based and collaborative filtering methods. The hybrid model integrates information from both user behavior and book attributes, resulting in more accurate and diverse suggestions. We also conduct comprehensive model evaluation to assess the effectiveness of this combined approach.\n",
    "\n",
    "Throughout the notebook, we will evaluate models using appropriate metrics such as RMSE, Precision@K, Recall@K, MAP, and NDCG to measure both prediction accuracy and ranking quality. By comparing these metrics, we aim to identify the best performing model that balances recommendation relevance and user satisfaction.\n",
    "\n",
    "By the end of this notebook, we aim to:\n",
    "- Demonstrate the value of collaborative and hybrid recommendation strategies.\n",
    "- Evaluate and compare model performance using relevant metrics.\n",
    "- Highlight the practical benefits and potential improvements for real-world book recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf5786-c929-4de6-9714-e6119435bd2a",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "## Importing Libraries \n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d275cbd-f2aa-4f7f-befb-9465fd678df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling & Utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Data')\n",
    "\n",
    "from data_utils import (  # Custom utility functions\n",
    "    import_csv, \n",
    "    generate_data_dictionary, \n",
    "    define_df_settings  \n",
    ")\n",
    "\n",
    "# Machine Learning Pipeline\n",
    "# Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    StandardScaler, \n",
    "    FunctionTransformer, \n",
    "    LabelEncoder\n",
    ")\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "# Model Training & Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Recommendation System\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Progress Tracking\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # Enable pandas progress tracking\n",
    "\n",
    "# Text Processing Utilities\n",
    "import re  # Regular expressions\n",
    "\n",
    "# Warning Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Pandas Display Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from surprise import Dataset, Reader, SVD, dump\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b0676-94bb-42ba-b8c6-e29744837a02",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "## Loading the Dataset\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfe297a9-8edc-4b46-ac9e-5a01091fda9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported data from cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading the clean dataset \n",
    "df = import_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e28d56c-1452-42bb-bf68-a52aa237e6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Total_num_of_ratings</th>\n",
       "      <th>Avg_ratings</th>\n",
       "      <th>Avg_ratings_excluding_zero</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year_Category</th>\n",
       "      <th>Publication_year</th>\n",
       "      <th>User_id</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1558746218</td>\n",
       "      <td>A Second Chicken Soup for the Woman's Soul (Chicken Soup for the Soul Series)</td>\n",
       "      <td>Jack Canfield</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7.79</td>\n",
       "      <td>Health Communications</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1998</td>\n",
       "      <td>8</td>\n",
       "      <td>26-32</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>http://images.amazon.com/images/P/1558746218.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.93</td>\n",
       "      <td>7.67</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>2000-2009</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>26-32</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1991</td>\n",
       "      <td>8</td>\n",
       "      <td>26-32</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.27</td>\n",
       "      <td>7.83</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>26-32</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1881320189</td>\n",
       "      <td>Goodbye to the Buttermilk Sky</td>\n",
       "      <td>Julia Oliver</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>River City Pub</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>26-32</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>http://images.amazon.com/images/P/1881320189.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  \\\n",
       "0  1558746218   \n",
       "1  0002005018   \n",
       "2  0060973129   \n",
       "3  0374157065   \n",
       "4  1881320189   \n",
       "\n",
       "                                                                                                Title  \\\n",
       "0                       A Second Chicken Soup for the Woman's Soul (Chicken Soup for the Soul Series)   \n",
       "1                                                                                        Clara Callan   \n",
       "2                                                                                Decision in Normandy   \n",
       "3  Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It   \n",
       "4                                                                       Goodbye to the Buttermilk Sky   \n",
       "\n",
       "                 Author  Ratings  Total_num_of_ratings  Avg_ratings  \\\n",
       "0         Jack Canfield        0                    56         3.89   \n",
       "1  Richard Bruce Wright        5                    14         4.93   \n",
       "2          Carlo D'Este        0                     3         5.00   \n",
       "3      Gina Bari Kolata        0                    11         4.27   \n",
       "4          Julia Oliver        7                     3         4.67   \n",
       "\n",
       "   Avg_ratings_excluding_zero              Publisher Year_Category  \\\n",
       "0                        7.79  Health Communications     1980-1999   \n",
       "1                        7.67  HarperFlamingo Canada     2000-2009   \n",
       "2                        7.50        HarperPerennial     1980-1999   \n",
       "3                        7.83   Farrar Straus Giroux     1980-1999   \n",
       "4                        7.00         River City Pub     1980-1999   \n",
       "\n",
       "   Publication_year  User_id Age_Category     City    State Country  \\\n",
       "0              1998        8        26-32  timmins  ontario  canada   \n",
       "1              2001        8        26-32  timmins  ontario  canada   \n",
       "2              1991        8        26-32  timmins  ontario  canada   \n",
       "3              1999        8        26-32  timmins  ontario  canada   \n",
       "4              1994        8        26-32  timmins  ontario  canada   \n",
       "\n",
       "                                                      Image_URL  \n",
       "0  http://images.amazon.com/images/P/1558746218.01.LZZZZZZZ.jpg  \n",
       "1  http://images.amazon.com/images/P/0002005018.01.LZZZZZZZ.jpg  \n",
       "2  http://images.amazon.com/images/P/0060973129.01.LZZZZZZZ.jpg  \n",
       "3  http://images.amazon.com/images/P/0374157065.01.LZZZZZZZ.jpg  \n",
       "4  http://images.amazon.com/images/P/1881320189.01.LZZZZZZZ.jpg  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf06e37-744b-45e5-8f48-feed8b2a1334",
   "metadata": {},
   "source": [
    "<a id=\"dict\"></a>\n",
    "## Data Dictionary\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca74598-c2b2-43cd-a925-42e7e6750148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Value Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISBN</td>\n",
       "      <td>object</td>\n",
       "      <td>International Standard Book Number, unique identifier for books</td>\n",
       "      <td>149831</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title</td>\n",
       "      <td>object</td>\n",
       "      <td>The title of the book</td>\n",
       "      <td>135563</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Author</td>\n",
       "      <td>object</td>\n",
       "      <td>The name of the book's author</td>\n",
       "      <td>62110</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ratings</td>\n",
       "      <td>int64</td>\n",
       "      <td>User's rating of the book, scale of 1-10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total_num_of_ratings</td>\n",
       "      <td>int64</td>\n",
       "      <td>Total number of ratings for the book</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2502)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg_ratings</td>\n",
       "      <td>float64</td>\n",
       "      <td>Average rating score for the book</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.11, 10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avg_ratings_excluding_zero</td>\n",
       "      <td>float64</td>\n",
       "      <td>Average rating score for the book excluding 0 values</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Publisher</td>\n",
       "      <td>object</td>\n",
       "      <td>The name of the book's publisher</td>\n",
       "      <td>11573</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Year_Category</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorized time period of publication</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Publication_year</td>\n",
       "      <td>int64</td>\n",
       "      <td>The year the book was published</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>User_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>Unique identifier for each user</td>\n",
       "      <td>88091</td>\n",
       "      <td>0</td>\n",
       "      <td>(8, 278854)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Age_Category</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorized Age into age ranges</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>City</td>\n",
       "      <td>object</td>\n",
       "      <td>City where the user is located</td>\n",
       "      <td>14213</td>\n",
       "      <td>12751</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>State</td>\n",
       "      <td>object</td>\n",
       "      <td>State or region where the user is located</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Country</td>\n",
       "      <td>object</td>\n",
       "      <td>Country where the user is located</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Image_URL</td>\n",
       "      <td>object</td>\n",
       "      <td>URL link to the book's cover image</td>\n",
       "      <td>149711</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Column Name Data Type  \\\n",
       "0                         ISBN    object   \n",
       "1                        Title    object   \n",
       "2                       Author    object   \n",
       "3                      Ratings     int64   \n",
       "4         Total_num_of_ratings     int64   \n",
       "5                  Avg_ratings   float64   \n",
       "6   Avg_ratings_excluding_zero   float64   \n",
       "7                    Publisher    object   \n",
       "8                Year_Category    object   \n",
       "9             Publication_year     int64   \n",
       "10                     User_id     int64   \n",
       "11                Age_Category    object   \n",
       "12                        City    object   \n",
       "13                       State    object   \n",
       "14                     Country    object   \n",
       "15                   Image_URL    object   \n",
       "\n",
       "                                                        Description  \\\n",
       "0   International Standard Book Number, unique identifier for books   \n",
       "1                                             The title of the book   \n",
       "2                                     The name of the book's author   \n",
       "3                          User's rating of the book, scale of 1-10   \n",
       "4                              Total number of ratings for the book   \n",
       "5                                 Average rating score for the book   \n",
       "6              Average rating score for the book excluding 0 values   \n",
       "7                                  The name of the book's publisher   \n",
       "8                            Categorized time period of publication   \n",
       "9                                   The year the book was published   \n",
       "10                                  Unique identifier for each user   \n",
       "11                                  Categorized Age into age ranges   \n",
       "12                                   City where the user is located   \n",
       "13                        State or region where the user is located   \n",
       "14                                Country where the user is located   \n",
       "15                               URL link to the book's cover image   \n",
       "\n",
       "    Unique Values  Missing Values   Value Range  \n",
       "0          149831               0           N/A  \n",
       "1          135563               0           N/A  \n",
       "2           62110               0           N/A  \n",
       "3              11               0       (0, 10)  \n",
       "4             377               0     (1, 2502)  \n",
       "5             710               0  (0.11, 10.0)  \n",
       "6             418               0   (1.0, 10.0)  \n",
       "7           11573               0           N/A  \n",
       "8               7               0           N/A  \n",
       "9             100               0     (0, 2020)  \n",
       "10          88091               0   (8, 278854)  \n",
       "11              6               0           N/A  \n",
       "12          14213           12751           N/A  \n",
       "13           1860               0           N/A  \n",
       "14            388               0           N/A  \n",
       "15         149711               0           N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict = generate_data_dictionary(df)\n",
    "display(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f65adb-e3d1-4c63-ae76-895b73432c86",
   "metadata": {},
   "source": [
    "<a id=\"funk\"></a>\n",
    "## Collabertaive Filtering using FunkSVD Model\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6354fa8-97e2-4d29-b58e-af8ffe727de8",
   "metadata": {},
   "source": [
    "Let's first refresh our memeory on what the cleaned dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f71fb0e-b370-4e1a-9d35-a94b3acacf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (851505, 16)\n",
      "Number of Unique Users: 88091\n",
      "Number of Unique Books: 149831\n"
     ]
    }
   ],
   "source": [
    "# Seeing the shape of the dataframe as well as the unique number of unique users and books\n",
    "print('Shape: ', df.shape)\n",
    "print('Number of Unique Users:',len(df['User_id'].unique()))\n",
    "print('Number of Unique Books:',len(df['ISBN'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f6f0f4-c7e1-4542-a6ae-b5726a76e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:0\n",
      "Max:10\n"
     ]
    }
   ],
   "source": [
    "# Check the min and max value of rating columns\n",
    "print(f'Min:{df[\"Ratings\"].min()}')\n",
    "print(f'Max:{df[\"Ratings\"].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4c1fa1-e83e-4f66-842f-202262faf0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0 ratings in the dataset: 467668\n"
     ]
    }
   ],
   "source": [
    "# Checking the count of ratings that are 0\n",
    "print(f'Number of 0 ratings in the dataset: {(df[\"Ratings\"] == 0).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfc8a3-700e-474d-a345-62dd0183cc46",
   "metadata": {},
   "source": [
    "Earlier, we removed zero ratings from our dataset, except in cases where a book had both zero and non-zero ratings from different users. As a result, we currently have 467,668 books with at least one zero rating, but these books also have other ratings from other users. This is not a problem, as we will apply additional filtering steps later. This check was simply to verify the current state of our data. Let's dive into out collabartaive filtering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08495d-1b7b-43b2-895e-191401ede5e1",
   "metadata": {},
   "source": [
    "**Collaborative filtering** is a technique widely used in recommender systems to suggest items (such as movies, books, or products) to users based on the preferences and behaviors of other users with similar tastes. The fundamental idea is that if two users have agreed in their evaluation of certain items in the past, they are likely to agree again in the future.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "- **User-Item Matrix:** The core of collaborative filtering is a matrix where rows represent users, columns represent items, and each cell contains a rating or interaction (explicit or implicit) between a user and an item. In real-world scenarios, this matrix is often sparse because most users interact with only a small subset of items.\n",
    "- **User-Based vs. Item-Based Filtering:**\n",
    "  - *User-based*: Finds users similar to the target user and recommends items those similar users liked.\n",
    "  - *Item-based*: Finds items similar to those the target user has liked and recommends those.\n",
    "- **Similarity Metrics:** Common ways to measure similarity include cosine similarity and Pearson correlation coefficient, both of which assess how closely users or items are related in terms of their ratings or interactions.\n",
    "\n",
    "### Matrix Factorization and FunkSVD\n",
    "\n",
    "Matrix factorization is a powerful approach for collaborative filtering, especially when dealing with large, sparse user-item matrices[6]. The goal is to decompose the original user-item matrix into lower-dimensional matrices that capture latent features of users and items.\n",
    "\n",
    "### How FunkSVD Works\n",
    "\n",
    "**FunkSVD** is a powerful solution for handling large, sparse matrices in collaborative filtering. Instead of directly comparing users or items, FunkSVD learns latent factors that represent underlying user preferences and item characteristics. Here is how it works:\n",
    "\n",
    "- **Objective:** Factorize the user-item matrix $ R $ (with users as rows and items as columns) into two lower-dimensional matrices:\n",
    "  - $ U $: User-feature matrix (users × latent factors)\n",
    "  - $ V $: Item-feature matrix (items × latent factors)\n",
    "- **Latent Factors:** These are hidden features that capture underlying patterns in user preferences and item characteristics.\n",
    "- **Prediction:** The predicted rating for user $ i $ and item $ j $ is computed as the dot product of the corresponding user and item latent feature vectors:\n",
    "  $$\n",
    "  \\hat{R}_{ij} = U_i \\cdot V_j^T\n",
    "  $$\n",
    "- **Optimization:** FunkSVD uses stochastic gradient descent to minimize the difference between observed ratings and predicted ratings, updating the latent features to best reconstruct the known entries in the user-item matrix.\n",
    "\n",
    "**Advantages of FunkSVD**\n",
    "- Handles Sparse Data: Efficiently learns from limited user-item interactions.\n",
    "- Scalable: Suitable for large datasets.\n",
    "- Captures Hidden Patterns: Learns latent features that may not be obvious from explicit data.\n",
    "\n",
    "**Challenges and Considerations**\n",
    "- Cold Start: New users or items with no interactions are hard to recommend for.\n",
    "- Data Sparsity: Very sparse matrices can make learning latent factors more difficult.\n",
    "- Popularity Bias: Tends to recommend popular items, potentially ignoring niche interes\n",
    "\n",
    "**In summary:** Collaborative filtering leverages patterns in user behavior to make recommendations, and FunkSVD is a matrix factorization technique that efficiently learns latent features from sparse user-item data to predict unknown preferences.\n",
    "\n",
    "Let's first start by filtering our dataset a little so that we can make accurate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bc18d98-6a79-4306-bd8e-7c39b5f93e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter users with more than 200 ratings\n",
    "user_counts = df['User_id'].value_counts()\n",
    "active_users = user_counts[user_counts > 200].index\n",
    "df_filtered = df[df['User_id'].isin(active_users)]\n",
    "\n",
    "# 2. Filter books with more than 20 ratings\n",
    "book_counts = df_filtered['ISBN'].value_counts()\n",
    "popular_books = book_counts[book_counts > 20].index\n",
    "df_filtered = df_filtered[df_filtered['ISBN'].isin(popular_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cae59276-daaf-4cc5-92db-0e03ff345636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Total_num_of_ratings</th>\n",
       "      <th>Avg_ratings</th>\n",
       "      <th>Avg_ratings_excluding_zero</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year_Category</th>\n",
       "      <th>Publication_year</th>\n",
       "      <th>User_id</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0451524934</td>\n",
       "      <td>1984</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>9</td>\n",
       "      <td>283</td>\n",
       "      <td>4.47</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Signet Book</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1990</td>\n",
       "      <td>254</td>\n",
       "      <td>18-25</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>United States</td>\n",
       "      <td>http://images.amazon.com/images/P/0451524934.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0446527785</td>\n",
       "      <td>A Bend in the Road</td>\n",
       "      <td>Nicholas Sparks</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>3.39</td>\n",
       "      <td>7.46</td>\n",
       "      <td>Warner Books</td>\n",
       "      <td>2000-2009</td>\n",
       "      <td>2001</td>\n",
       "      <td>254</td>\n",
       "      <td>18-25</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>United States</td>\n",
       "      <td>http://images.amazon.com/images/P/0446527785.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0684874350</td>\n",
       "      <td>ANGELA'S ASHES</td>\n",
       "      <td>Frank McCourt</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>4.08</td>\n",
       "      <td>8.36</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>1980-1999</td>\n",
       "      <td>1996</td>\n",
       "      <td>254</td>\n",
       "      <td>18-25</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>United States</td>\n",
       "      <td>http://images.amazon.com/images/P/0684874350.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0380789035</td>\n",
       "      <td>American Gods</td>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>10</td>\n",
       "      <td>302</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>2000-2009</td>\n",
       "      <td>2002</td>\n",
       "      <td>254</td>\n",
       "      <td>18-25</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>United States</td>\n",
       "      <td>http://images.amazon.com/images/P/0380789035.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0380973650</td>\n",
       "      <td>American Gods: A Novel</td>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>9</td>\n",
       "      <td>65</td>\n",
       "      <td>3.31</td>\n",
       "      <td>8.27</td>\n",
       "      <td>William Morrow</td>\n",
       "      <td>2000-2009</td>\n",
       "      <td>2001</td>\n",
       "      <td>254</td>\n",
       "      <td>18-25</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>United States</td>\n",
       "      <td>http://images.amazon.com/images/P/0380973650.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISBN                   Title           Author  Ratings  \\\n",
       "284  0451524934                    1984    George Orwell        9   \n",
       "286  0446527785      A Bend in the Road  Nicholas Sparks        0   \n",
       "288  0684874350          ANGELA'S ASHES    Frank McCourt        0   \n",
       "293  0380789035           American Gods      Neil Gaiman       10   \n",
       "294  0380973650  American Gods: A Novel      Neil Gaiman        9   \n",
       "\n",
       "     Total_num_of_ratings  Avg_ratings  Avg_ratings_excluding_zero  \\\n",
       "284                   283         4.47                        8.78   \n",
       "286                   343         3.39                        7.46   \n",
       "288                   279         4.08                        8.36   \n",
       "293                   302         4.01                        8.01   \n",
       "294                    65         3.31                        8.27   \n",
       "\n",
       "          Publisher Year_Category  Publication_year  User_id Age_Category  \\\n",
       "284     Signet Book     1980-1999              1990      254        18-25   \n",
       "286    Warner Books     2000-2009              2001      254        18-25   \n",
       "288        Scribner     1980-1999              1996      254        18-25   \n",
       "293     HarperTorch     2000-2009              2002      254        18-25   \n",
       "294  William Morrow     2000-2009              2001      254        18-25   \n",
       "\n",
       "            City      State        Country  \\\n",
       "284  minneapolis  minnesota  United States   \n",
       "286  minneapolis  minnesota  United States   \n",
       "288  minneapolis  minnesota  United States   \n",
       "293  minneapolis  minnesota  United States   \n",
       "294  minneapolis  minnesota  United States   \n",
       "\n",
       "                                                        Image_URL  \n",
       "284  http://images.amazon.com/images/P/0451524934.01.LZZZZZZZ.jpg  \n",
       "286  http://images.amazon.com/images/P/0446527785.01.LZZZZZZZ.jpg  \n",
       "288  http://images.amazon.com/images/P/0684874350.01.LZZZZZZZ.jpg  \n",
       "293  http://images.amazon.com/images/P/0380789035.01.LZZZZZZZ.jpg  \n",
       "294  http://images.amazon.com/images/P/0380973650.01.LZZZZZZZ.jpg  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555adcb-414f-4068-aab8-4182d8ae3dd7",
   "metadata": {},
   "source": [
    "#### Why This Filtering Makes Sense\n",
    "\n",
    "##### 1. **Improves Data Quality**\n",
    "- **Active users** (those who rate a lot) provide more information about their preferences, making it easier for the model to learn their tastes.\n",
    "- **Popular books** (those with many ratings) have more reliable average ratings and user feedback, reducing the impact of outliers or noise.\n",
    "\n",
    "##### 2. **Reduces Sparsity**\n",
    "- Collaborative filtering models like FunkSVD struggle with very sparse data (lots of missing ratings).\n",
    "- Filtering out users and books with few ratings ensures the user-item matrix is denser, leading to better model performance.\n",
    "\n",
    "##### 3. **Mitigates Cold Start Problems**\n",
    "- Users or books with very few ratings (cold start) are hard to model accurately with FunkSVD, which relies on patterns in the data.\n",
    "- By filtering, you focus on the \"core\" of your dataset where the model can learn meaningful patterns.\n",
    "\n",
    "#### Potential Trade-offs\n",
    "\n",
    "- **Smaller dataset:** You will lose a significant portion of users and books, but the remaining data will be higher quality.\n",
    "- **Less coverage:** The system won’t make recommendations for users/books outside this filtered set.\n",
    "- **Better accuracy:** For the remaining users and books, our recommendations will likely be more accurate and reliable.\n",
    "\n",
    "It will help our FunkSVD model perform better by focusing on users and books with enough data to learn from.\n",
    "\n",
    "#### How did we determine these values? \n",
    "\n",
    "- 200 is a high enough number to ensure activity but not so high that you lose too many users. It’s a common starting point in large datasets.\n",
    "- 20 is a reasonable compromise between keeping enough books in the dataset and ensuring each has sufficient data.\n",
    "\n",
    "We use 200 and 20 as sensible defaults to focus on active users and popular books, which improves model reliability and performance. We can and will adjust these numbers in the future to itertate the model and find better more reliable values. This is just a starting point from looking at our dataset spread and trying to run the first iteration on this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55f4124c-221c-4a49-b59c-0f870badb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep necessary columns\n",
    "ratings_df = df_filtered[['User_id', 'ISBN', 'Ratings']]\n",
    "\n",
    "# Define the reader\n",
    "reader = Reader(rating_scale=(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54b12761-3bce-4826-8635-c89932936ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a sample df for the GridSearchCV. Take a random sample of 20,000 rows for hyperparameter tuning to save time. \n",
    "sample_df = ratings_df.sample(n=20000, random_state=42)\n",
    "\n",
    "#loading Pandas Sample DataFrame into a Surprise Dataset object\n",
    "sample_data = Dataset.load_from_df(sample_df, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d11f1c-b540-4178-afe7-2397205be347",
   "metadata": {},
   "source": [
    "As we did for other models we can do some hyperparameter tuning to find the best paramaters for our model to learn from. What are these parameters? \n",
    "\n",
    "- **features**: The number of latent features (also called factors or dimensions) to learn. Higher values allow the model to capture more complex patterns in user-item interactions, but can increase the risk of overfitting and computational cost.\n",
    "- **iterations**: The number of training passes (epochs) over the data. More iterations allow the model to converge more fully, but excessive iterations can lead to overfitting or unnecessary computation.\n",
    "- **reg (regularization factor)**: Penalizes large values in the latent feature matrices to reduce overfitting. This can be a single value or a tuple for separate user/item regularization. Higher regularization makes the model more conservative\n",
    "- **lrate (learning rate)**:Controls the step size during stochastic gradient descent. A higher learning rate speeds up training but can cause instability, while a lower rate leads to slower, more stable convergence.\n",
    "- **bias**:Whether to include user and item bias terms in the model. Setting this to `True` fits a bias model, which helps account for systematic differences in user or item rating behavior (e.g., some users rate higher on average).\n",
    "\n",
    "Now, let't do a GridSearch on 3 cross validation sets to find the best parameters for out mdoel and then apply those to out entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c71e4f9-ff82-43d1-8327-1ca68216e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 3.492609219765501\n",
      "Best params: {'n_factors': 20, 'lr_all': 0.005, 'reg_all': 0.1, 'n_epochs': 30, 'biased': False}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.05, 0.1],\n",
    "    'n_epochs': [10, 20, 30],\n",
    "    'biased': [False]\n",
    "}\n",
    "\n",
    "# Grid search on the sample\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "gs.fit(sample_data)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
    "print(\"Best params:\", gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b11454ff-fcdb-4e2c-b7e8-713fdfba68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the full Pandas DataFrame into a Surprise Dataset object\n",
    "full_data = Dataset.load_from_df(ratings_df, reader)\n",
    "\n",
    "# Train/Test Split on Full Filtered Data\n",
    "trainset, testset = train_test_split(full_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d770c43-f26a-4c12-97ee-9535e8bd6540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunkSVD model saved to 'models/funkSVD_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Using the best parameters from grid search on the train set \n",
    "best_params = gs.best_params['rmse']\n",
    "algo = SVD(\n",
    "    n_factors=best_params['n_factors'],\n",
    "    lr_all=best_params['lr_all'],\n",
    "    reg_all=best_params['reg_all'],\n",
    "    random_state=42\n",
    ")\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Saving the trained model immediately after training\n",
    "dump.dump('../models/funkSVD_model.pkl', algo=algo)\n",
    "\n",
    "print(\"FunkSVD model saved to 'models/funkSVD_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bbd2ed2-d8a8-4da2-b3a1-86b7fb859910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0312980140', 7.023044089908027), ('0449005615', 6.862009198441903), ('0679751521', 6.063059278127707), ('0380978415', 6.050993710071273), ('0316788228', 5.789091409494556), ('0345313860', 5.7606733760118916), ('0877733759', 5.685910907995773), ('0394800168', 5.675154054755483), ('0385493800', 5.1610690045529015), ('0312306326', 5.108326888089161)]\n"
     ]
    }
   ],
   "source": [
    "# Selecting a user for whom you want to make recommendations.\n",
    "user_id = ratings_df['User_id'].iloc[0]  #  Here, we simply pick the first user in the DataFrame as an example.\n",
    "\n",
    "# Getting a list of all unique books (ISBNs) in our dataset and looking at which books the user have already rated and not rated \n",
    "all_books = ratings_df['ISBN'].unique()\n",
    "user_books = ratings_df[ratings_df['User_id'] == user_id]['ISBN']\n",
    "books_to_predict = [isbn for isbn in all_books if isbn not in user_books.values]\n",
    "\n",
    "# For each book the user hasn't rated, use the trained FunkSVD model to predict the user's rating.\n",
    "predictions = [algo.predict(user_id, isbn) for isbn in books_to_predict]\n",
    "top_n = sorted(predictions, key=lambda x: x.est, reverse=True)[:10]\n",
    "recommended_books = [(pred.iid, pred.est) for pred in top_n]\n",
    "\n",
    "# Printing out the recommended books (ISBNs and predicted ratings).\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1c9ecbe-3764-4911-8d33-559a27e0038b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Predicted_Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0312980140</td>\n",
       "      <td>7.023044</td>\n",
       "      <td>Seven Up (A Stephanie Plum Novel)</td>\n",
       "      <td>Janet Evanovich</td>\n",
       "      <td>St. Martin's Paperbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0449005615</td>\n",
       "      <td>6.862009</td>\n",
       "      <td>Seabiscuit: An American Legend</td>\n",
       "      <td>LAURA HILLENBRAND</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0679751521</td>\n",
       "      <td>6.063059</td>\n",
       "      <td>Midnight in the Garden of Good and Evil</td>\n",
       "      <td>John Berendt</td>\n",
       "      <td>Vintage Books USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0380978415</td>\n",
       "      <td>6.050994</td>\n",
       "      <td>Fluke : Or, I Know Why the Winged Whale Sings</td>\n",
       "      <td>Christopher Moore</td>\n",
       "      <td>William Morrow &amp;amp; Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0316788228</td>\n",
       "      <td>5.789091</td>\n",
       "      <td>The Pilot's Wife</td>\n",
       "      <td>Anita Shreve</td>\n",
       "      <td>Little, Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0345313860</td>\n",
       "      <td>5.760673</td>\n",
       "      <td>The Vampire Lestat (Vampire Chronicles, Book II)</td>\n",
       "      <td>ANNE RICE</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0877733759</td>\n",
       "      <td>5.685911</td>\n",
       "      <td>Writing Down the Bones</td>\n",
       "      <td>NATALIE GOLDBERG</td>\n",
       "      <td>Shambhala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0394800168</td>\n",
       "      <td>5.675154</td>\n",
       "      <td>Green Eggs and Ham (I Can Read It All by Myself Beginner Books)</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>Random House Books for Young Readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0385493800</td>\n",
       "      <td>5.161069</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>Doubleday Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0312306326</td>\n",
       "      <td>5.108327</td>\n",
       "      <td>Visions of Sugar Plums</td>\n",
       "      <td>Janet Evanovich</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  Predicted_Rating  \\\n",
       "0  0312980140          7.023044   \n",
       "1  0449005615          6.862009   \n",
       "2  0679751521          6.063059   \n",
       "3  0380978415          6.050994   \n",
       "4  0316788228          5.789091   \n",
       "5  0345313860          5.760673   \n",
       "6  0877733759          5.685911   \n",
       "7  0394800168          5.675154   \n",
       "8  0385493800          5.161069   \n",
       "9  0312306326          5.108327   \n",
       "\n",
       "                                                             Title  \\\n",
       "0                                Seven Up (A Stephanie Plum Novel)   \n",
       "1                                   Seabiscuit: An American Legend   \n",
       "2                          Midnight in the Garden of Good and Evil   \n",
       "3                    Fluke : Or, I Know Why the Winged Whale Sings   \n",
       "4                                                 The Pilot's Wife   \n",
       "5                 The Vampire Lestat (Vampire Chronicles, Book II)   \n",
       "6                                           Writing Down the Bones   \n",
       "7  Green Eggs and Ham (I Can Read It All by Myself Beginner Books)   \n",
       "8                                                    The Testament   \n",
       "9                                           Visions of Sugar Plums   \n",
       "\n",
       "              Author                             Publisher  \n",
       "0    Janet Evanovich               St. Martin's Paperbacks  \n",
       "1  LAURA HILLENBRAND                      Ballantine Books  \n",
       "2       John Berendt                     Vintage Books USA  \n",
       "3  Christopher Moore          William Morrow &amp; Company  \n",
       "4       Anita Shreve                         Little, Brown  \n",
       "5          ANNE RICE                      Ballantine Books  \n",
       "6   NATALIE GOLDBERG                             Shambhala  \n",
       "7          Dr. Seuss  Random House Books for Young Readers  \n",
       "8       John Grisham                       Doubleday Books  \n",
       "9    Janet Evanovich                    St. Martin's Press  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "rec_df = pd.DataFrame(recommended_books, columns=['ISBN', 'Predicted_Rating'])\n",
    "\n",
    "# Drop duplicates in your book metadata DataFrame to avoid merge issues\n",
    "book_metadata = df_filtered[['ISBN', 'Title', 'Author', 'Publisher']].drop_duplicates('ISBN')\n",
    "\n",
    "# Merge recommendations with metadata\n",
    "final_recommendations = rec_df.merge(book_metadata, on='ISBN', how='left')\n",
    "\n",
    "final_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccef68-d05c-4c3d-a234-153a69888b5f",
   "metadata": {},
   "source": [
    "Here, we have used the FunkSVD model to predict ratings for the first user on all books they haven’t rated yet. The model learns from the user’s previous ratings and overall patterns in the data, allowing it to estimate how much the user might enjoy other books. These predicted ratings help us recommend new books tailored to the user’s preferences. \n",
    "\n",
    "We see that the model is providing recommendations, but how good at these recommendations? To look at how good are model is predicting ratings, let's evaluate the models performance and see!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e28fdf-33ba-4b97-8e67-9711a9bd9f1e",
   "metadata": {},
   "source": [
    "<a id=\"eval1\"></a>\n",
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69737f84-f5b4-485b-ae37-62509367722a",
   "metadata": {},
   "source": [
    "For the above we want to see if the ratings we have predivted for the used are accurate to what they would end up rating a book. So lets's first look at the root mean suared error (RMSE). So what exactly is RMSE and how to we calculate this?\n",
    "\n",
    "- **What it measures:**  \n",
    "  RMSE quantifies how close your model’s predicted ratings are to the actual user ratings. It’s the square root of the average of the squared differences between the predicted and actual ratings.\n",
    "- **How it’s calculated:**  \n",
    "  $$\n",
    "  RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (r_i - \\hat{r}_i)^2}\n",
    "  $$\n",
    "  Where $ r_i $ is the true rating, $ \\hat{r}_i $ is the predicted rating, and $ N $ is the number of predictions.\n",
    "- **Interpretation:**  \n",
    "  - Lower RMSE means your predictions are closer to the actual ratings.\n",
    "  - RMSE penalizes large errors more than small ones (because of the squaring), so it’s sensitive to outliers.\n",
    "- **When to use:**  \n",
    "  - RMSE is best when you care about accurately predicting the numeric value of ratings (e.g., predicting if a user will rate a book 3 or 5 stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4af971ed-9778-4653-82f7-92769bdafdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.2648\n",
      "Test RMSE: 3.2648\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on Test Set\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354bea6-b3ed-4116-b456-3bbf82fd14ef",
   "metadata": {},
   "source": [
    "Here, we observe that our FunkSVD model achieves an **RMSE (Root Mean Squared Error) of 3.26 on the test set**. This metric tells us, on average, how much our predicted ratings deviate from the actual ratings that users gave to books they have read. In practical terms, an RMSE of 3.26 means that, on average, our model’s predictions are within about 3.26 rating points of the true user ratings.\n",
    "\n",
    "A lower RMSE indicates that the model’s predictions are closely aligned with real user preferences, suggesting that our recommender system is able to capture meaningful patterns in the data. While the interpretation of “good” RMSE depends on the scale of your ratings (our ratings are on a 1–10 scale, an RMSE of 3.26 is moderate), this result demonstrates that the model is making reasonably accurate predictions about how users would rate books they haven’t read yet.\n",
    "\n",
    "Ultimately, this level of accuracy means our recommendations are likely to be relevant and useful to users, helping them discover new books that match their tastes. However, there is still room for improvement, and further tuning or incorporating additional features could help reduce the RMSE even more, leading to even better recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1c9ef42-6bdd-484b-a0b0-ee6eadecd198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouping predictions by user\n",
    "user_preds = defaultdict(list)\n",
    "for pred in predictions:\n",
    "    user_preds[pred.uid].append(pred)\n",
    "\n",
    "# Computing RMSE per user\n",
    "user_rmses = []\n",
    "for uid, preds in user_preds.items():\n",
    "    true = np.array([p.r_ui for p in preds])\n",
    "    est = np.array([p.est for p in preds])\n",
    "    rmse = np.sqrt(np.mean((true - est) ** 2))\n",
    "    user_rmses.append(rmse)\n",
    "\n",
    "# Plotting histogram of user RMSEs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(user_rmses, bins=30, edgecolor='black')\n",
    "plt.xlabel('User RMSE')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.title('Distribution of RMSE per User')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb6841-be1f-4857-8ff4-2a1215e73577",
   "metadata": {},
   "source": [
    "This graph shows the **distribution of RMSE (Root Mean Squared Error) per user** for your recommendation model.\n",
    "\n",
    "##### **What does this mean?**\n",
    "\n",
    "- **X-axis (User RMSE):**  \n",
    "  The RMSE value for individual users. Lower values mean the model’s predicted ratings are closer to the actual ratings for that user; higher values mean the predictions are less accurate.\n",
    "- **Y-axis (Number of Users):**  \n",
    "  The number of users who have a particular RMSE value.\n",
    "\n",
    "##### **How to interpret this graph:**\n",
    "\n",
    "- Most users have a RMSE between about **2 and 5**, with the highest concentration around **3 to 4**. This means that for most users, the model’s predictions are, on average, 3–4 rating points away from the actual ratings.\n",
    "- There are a few users with very low RMSE (close to 1), meaning the model predicts their ratings very accurately.\n",
    "- There are also a few users with higher RMSE (above 5), indicating the model struggles to predict ratings accurately for these users.\n",
    "- The distribution is roughly bell-shaped but slightly right-skewed, suggesting that while the model works well for most users, there is a tail of users for whom prediction is more difficult.\n",
    "\n",
    "##### **What can you learn from this?**\n",
    "\n",
    "- **Consistency:** The model performs reasonably well for the majority of users, but not equally well for everyone.\n",
    "- **Outliers:** Investigating users with high RMSE could reveal patterns (e.g., users with unusual tastes or little data) that might help you further improve your model.\n",
    "- **Model quality:** If most RMSE values are low, your model is generally making accurate predictions.\n",
    "\n",
    "\n",
    "**In summary:**  \n",
    "This histogram helps you see how prediction accuracy varies across your user base, highlighting both the typical performance and the presence of users for whom the model may need improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "411c13ba-8a1e-4150-9489-6386fa850350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.263\n",
      "Recall@10: 0.522\n"
     ]
    }
   ],
   "source": [
    "K = 10  # You can set K to any value you want\n",
    "\n",
    "# Getting  top K recommendations for each user\n",
    "def get_top_k(predictions, k=10):\n",
    "    top_k = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est, true_r))\n",
    "    # Sort and keep top K for each user\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_k[uid] = user_ratings[:k]\n",
    "    return top_k\n",
    "\n",
    "top_k_recs = get_top_k(predictions, K)\n",
    "\n",
    "# Building a mapping of relevant items for each user (e.g., true rating >= 4)\n",
    "relevant = defaultdict(set)\n",
    "for uid, iid, true_r, est, _ in predictions:\n",
    "    if true_r >= 4:  # Adjust threshold as appropriate\n",
    "        relevant[uid].add(iid)\n",
    "\n",
    "# Calculating precision@K and recall@K for each user\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for uid, user_recs in top_k_recs.items():\n",
    "    recommended_iids = set([iid for iid, est, true_r in user_recs])\n",
    "    relevant_iids = relevant[uid]\n",
    "    n_rel_and_rec_k = len(recommended_iids & relevant_iids)\n",
    "    n_rec_k = K\n",
    "    n_rel = len(relevant_iids)\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k else 0\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel else 0\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "# Averaging over all users\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "\n",
    "print(f\"Precision@{K}: {mean_precision:.3f}\")\n",
    "print(f\"Recall@{K}: {mean_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c82204-deeb-4c11-b109-6dce339ae6b9",
   "metadata": {},
   "source": [
    "#### **What does this tell you about your model?** \n",
    "\n",
    "**Precision@10 (0.263)**:Our recommendations are moderately accurate—about a quarter of our top 10 suggestions are hits. There’s room for improvement, but this is a reasonable starting point for many real-world recommenders, especially with large catalogs.\n",
    "\n",
    "**Recall@10 (0.522)**:Our recommender is capturing over half of the items that users actually like in its top 10 suggestions. This means users are likely to see a good portion of the books they would enjoy.\n",
    "\n",
    "Our model’s top 10 recommendations are moderately precise and capture a good portion of what users actually like. This is a solid baseline and a good sign that our recommender is providing value, but further tuning could improve both precision and recall!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffbeea-546b-436f-988a-8a80ad86095e",
   "metadata": {},
   "source": [
    "#### **FCP: Fraction of Concordant Pairs**\n",
    "\n",
    "##### **What does FCP measure?**\n",
    "\n",
    "- **FCP** checks, for all possible pairs of items that a user has rated differently, whether the system’s predicted ranking matches the user’s true preference.\n",
    "- A **concordant pair** is when both the user and the system agree on which item is preferred.\n",
    "- A **discordant pair** is when the system’s ranking disagrees with the user’s actual preference.\n",
    "\n",
    "##### **How is FCP calculated?**\n",
    "\n",
    "$$\n",
    "FCP = \\frac{\\text{Number of Concordant Pairs}}{\\text{Number of Concordant Pairs} + \\text{Number of Discordant Pairs}}\n",
    "$$\n",
    "\n",
    "- **Concordant pair:** If a user prefers item $i$ over item $j$ (e.g., rated higher), and the system also predicts a higher score for $i$ than $j$.\n",
    "- **Discordant pair:** If the user prefers $i$ over $j$, but the system predicts $j$ over $i$.\n",
    "\n",
    "**FCP ranges from 0 to 1:**\n",
    "- **1** means perfect agreement between system and user preferences.\n",
    "- **0** means no agreement.\n",
    "\n",
    "\n",
    "##### **Why use FCP?**\n",
    "\n",
    "- FCP focuses on the *relative ordering* of items, not just the absolute rating values.\n",
    "- It is especially useful when the *ranking* of recommendations is more important than the exact predicted scores (such as in top-N recommendation lists).\n",
    "- FCP provides granular insight into how well your system captures user preferences at the pairwise level[1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c0a3307d-c218-4969-8552-1bfbaee4bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCP:  0.5013\n",
      "FCP: 0.501\n"
     ]
    }
   ],
   "source": [
    "print(f\"FCP: {accuracy.fcp(predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca56ca-f0fd-4396-8890-c8319b983308",
   "metadata": {},
   "source": [
    "In this project, our goal is to generate a shortlist of 5–10 books that each user is most likely to enjoy, using a personalized book recommendation system built with Python and machine learning. To evaluate how well our model selects these top book recommendations, we focused on precision@k and recall@k, which directly measure how many of the books in each user's shortlist are actually relevant and how well we cover the set of books they would like.\n",
    "\n",
    "While we also calculated the Fraction of Concordant Pairs (FCP), which measures the overall accuracy of item ranking across all possible book pairs, our observed FCP of approximately 0.501 suggests the model’s global ranking is only slightly better than random. However, because FCP considers all possible rankings and not just the top books presented to users, it is less informative for our specific objective of surfacing the best 5–10 book recommendations per user. For this reason, precision@k and recall@k remain the most useful metrics for guiding improvements to our book recommendation shortlist and ensuring users receive books they are likely to enjoy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d7e23-4165-41d7-a303-d7703a3dfd01",
   "metadata": {},
   "source": [
    "<a id=\"hybrid\"></a>\n",
    "## Hydrid Model \n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "775986e4-2bd6-4ba0-ac8b-c5f2d95c63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendation(\n",
    "    df, collab_model, user_id=None, user_query=None, top_n=5, alpha=0.5, emb_col='Text_emb'\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate hybrid book recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "        df: DataFrame with book metadata and embeddings\n",
    "        collab_model: Trained collaborative filtering model\n",
    "        user_id: (str) User ID, or None for new users\n",
    "        user_query: (str) Book title or ISBN the user likes\n",
    "        top_n: (int) Number of recommendations to return\n",
    "        alpha: (float) Weight for collaborative filtering (0-1)\n",
    "        emb_col: (str) Name of the embedding column to use (default 'Text_emb')\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top N recommendations\n",
    "    \"\"\"\n",
    "    # Map title to ISBN if needed\n",
    "    if not user_query:\n",
    "        raise ValueError(\"Please provide a book title or ISBN as user_query.\")\n",
    "    if user_query in df['ISBN'].values:\n",
    "        query_isbn = user_query\n",
    "    else:\n",
    "        match = df[df['Title'].str.lower() == user_query.lower()]\n",
    "        if not match.empty:\n",
    "            query_isbn = match.iloc[0]['ISBN']\n",
    "        else:\n",
    "            raise ValueError(\"Book not found in dataset.\")\n",
    "\n",
    "    # Content-based similarity\n",
    "    query_vec = df.loc[df['ISBN'] == query_isbn, emb_col].values[0].reshape(1, -1)\n",
    "    all_vecs = list(df[emb_col])\n",
    "    cos_sims = cosine_similarity(query_vec, all_vecs).flatten()\n",
    "    df['content_score'] = cos_sims\n",
    "\n",
    "    # Collaborative filtering (if user_id provided)\n",
    "    if user_id:\n",
    "        df['collab_score'] = df['ISBN'].apply(lambda x: collab_model.predict(user_id, x).est)\n",
    "    else:\n",
    "        df['collab_score'] = 0\n",
    "\n",
    "    # Normalize scores\n",
    "    scaler = MinMaxScaler()\n",
    "    df['content_score_norm'] = scaler.fit_transform(df[['content_score']])\n",
    "    if user_id:\n",
    "        df['collab_score_norm'] = scaler.fit_transform(df[['collab_score']])\n",
    "    else:\n",
    "        df['collab_score_norm'] = 0\n",
    "\n",
    "    # Hybrid score\n",
    "    df['hybrid_score'] = alpha * df['collab_score_norm'] + (1 - alpha) * df['content_score_norm']\n",
    "\n",
    "    # Show top recommendations\n",
    "    result = df.sort_values('hybrid_score', ascending=False)\n",
    "    return result[['Title', 'Author', 'Genre', 'hybrid_score']].head(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "516ada62-8da7-4b7c-9ccf-4a0ae131ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from surprise import dump\n",
    "\n",
    "# Load DataFrame\n",
    "with open('../models/book_title_embeddings_updated.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Load collaborative model\n",
    "_, collab_model = dump.load('../models/funkSVD_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78689532-c9f0-48a8-83dd-b791094872a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>hybrid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>The Hobbit</td>\n",
       "      <td>J R R Tolkien</td>\n",
       "      <td>Arkenstone, Battle of Five Armies, invisibility</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>The Hobbit (Leatherette Collector's Edition)</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Arkenstone, Battle of Five Armies, invisibility</td>\n",
       "      <td>0.425407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>The Hobbit (Young Adult edition, Sis cover)</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Arkenstone, Battle of Five Armies, invisibility</td>\n",
       "      <td>0.425407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>The Lord of the Rings</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>The Lord of the Rings, Fiction, Ficción</td>\n",
       "      <td>0.383867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>The Return of the King</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Elves, Hobbits, The Lord of the Rings</td>\n",
       "      <td>0.375115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>The Return of the King (The Lord of The Rings, Part 3)</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Elves, Hobbits, The Lord of the Rings</td>\n",
       "      <td>0.375115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>The Hobbit: Or There and Back Again</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Arkenstone, Battle of Five Armies, invisibility</td>\n",
       "      <td>0.373720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Title  \\\n",
       "1242                                              The Hobbit   \n",
       "5866            The Hobbit (Leatherette Collector's Edition)   \n",
       "8474             The Hobbit (Young Adult edition, Sis cover)   \n",
       "3532                                   The Lord of the Rings   \n",
       "8799                                  The Return of the King   \n",
       "4797  The Return of the King (The Lord of The Rings, Part 3)   \n",
       "3065                     The Hobbit: Or There and Back Again   \n",
       "\n",
       "                Author                                            Genre  \\\n",
       "1242     J R R Tolkien  Arkenstone, Battle of Five Armies, invisibility   \n",
       "5866  J. R. R. Tolkien  Arkenstone, Battle of Five Armies, invisibility   \n",
       "8474  J. R. R. Tolkien  Arkenstone, Battle of Five Armies, invisibility   \n",
       "3532  J. R. R. Tolkien          The Lord of the Rings, Fiction, Ficción   \n",
       "8799  J. R. R. Tolkien            Elves, Hobbits, The Lord of the Rings   \n",
       "4797  J. R. R. Tolkien            Elves, Hobbits, The Lord of the Rings   \n",
       "3065  J. R. R. Tolkien  Arkenstone, Battle of Five Armies, invisibility   \n",
       "\n",
       "      hybrid_score  \n",
       "1242      0.500000  \n",
       "5866      0.425407  \n",
       "8474      0.425407  \n",
       "3532      0.383867  \n",
       "8799      0.375115  \n",
       "4797      0.375115  \n",
       "3065      0.373720  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call your recommendation function\n",
    "hybrid_recommendation(df, collab_model, user_id=None, user_query=\"The Hobbit\", top_n=7, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "210df727-2c11-4008-a7fc-52f7e27a450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>hybrid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>The Blue Day Book</td>\n",
       "      <td>Bradley Trevor Greive</td>\n",
       "      <td>Melancholy, Conduct of life, Miscellanea</td>\n",
       "      <td>0.745484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>The Lion, the Witch, and the Wardrobe (The Chronicles of Narnia, Book 2)</td>\n",
       "      <td>C. S. Lewis</td>\n",
       "      <td>the Blitz, fauns, Turkish Delight</td>\n",
       "      <td>0.732695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Griffin &amp;amp; Sabine: An Extraordinary Correspondence</td>\n",
       "      <td>Nick Bantock</td>\n",
       "      <td>Imaginary letters, Toy and movable books, Specimens</td>\n",
       "      <td>0.716880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>Ghosts, Monsters, Vampires</td>\n",
       "      <td>0.677039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>The Hobbit : The Enchanting Prelude to The Lord of the Rings</td>\n",
       "      <td>J.R.R. TOLKIEN</td>\n",
       "      <td>Arkenstone, Battle of Five Armies, invisibility</td>\n",
       "      <td>0.660661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Book 5)</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>Children's Books/Ages 9-12 Fiction, Witches and warlocks, Juvenile audience</td>\n",
       "      <td>0.656387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>Fantasy fiction, orphans, foster homes</td>\n",
       "      <td>0.637233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>The Two Dead Girls (Green Mile Series)</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>horror fiction, fiction, death row inmates</td>\n",
       "      <td>0.631708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Mama Makes Up Her Mind: And Other Dangers of Southern Living</td>\n",
       "      <td>Bailey White</td>\n",
       "      <td>Social life and customs, Humor, Large type books</td>\n",
       "      <td>0.623541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>Hound Of The Far Side (Far Side Books, Collection No 7)</td>\n",
       "      <td>Gary Larson</td>\n",
       "      <td>Pictorial American wit and humor, Graphic novels, Comics and cartoons</td>\n",
       "      <td>0.620138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         Title  \\\n",
       "2166                                                         The Blue Day Book   \n",
       "1279  The Lion, the Witch, and the Wardrobe (The Chronicles of Narnia, Book 2)   \n",
       "1456                     Griffin &amp; Sabine: An Extraordinary Correspondence   \n",
       "140                             Harry Potter and the Sorcerer's Stone (Book 1)   \n",
       "137               The Hobbit : The Enchanting Prelude to The Lord of the Rings   \n",
       "87                          Harry Potter and the Order of the Phoenix (Book 5)   \n",
       "59                           Harry Potter and the Prisoner of Azkaban (Book 3)   \n",
       "1151                                    The Two Dead Girls (Green Mile Series)   \n",
       "976               Mama Makes Up Her Mind: And Other Dangers of Southern Living   \n",
       "3565                   Hound Of The Far Side (Far Side Books, Collection No 7)   \n",
       "\n",
       "                     Author  \\\n",
       "2166  Bradley Trevor Greive   \n",
       "1279            C. S. Lewis   \n",
       "1456           Nick Bantock   \n",
       "140           J. K. Rowling   \n",
       "137          J.R.R. TOLKIEN   \n",
       "87            J. K. Rowling   \n",
       "59            J. K. Rowling   \n",
       "1151           Stephen King   \n",
       "976            Bailey White   \n",
       "3565            Gary Larson   \n",
       "\n",
       "                                                                            Genre  \\\n",
       "2166                                     Melancholy, Conduct of life, Miscellanea   \n",
       "1279                                            the Blitz, fauns, Turkish Delight   \n",
       "1456                          Imaginary letters, Toy and movable books, Specimens   \n",
       "140                                                    Ghosts, Monsters, Vampires   \n",
       "137                               Arkenstone, Battle of Five Armies, invisibility   \n",
       "87    Children's Books/Ages 9-12 Fiction, Witches and warlocks, Juvenile audience   \n",
       "59                                         Fantasy fiction, orphans, foster homes   \n",
       "1151                                   horror fiction, fiction, death row inmates   \n",
       "976                              Social life and customs, Humor, Large type books   \n",
       "3565        Pictorial American wit and humor, Graphic novels, Comics and cartoons   \n",
       "\n",
       "      hybrid_score  \n",
       "2166      0.745484  \n",
       "1279      0.732695  \n",
       "1456      0.716880  \n",
       "140       0.677039  \n",
       "137       0.660661  \n",
       "87        0.656387  \n",
       "59        0.637233  \n",
       "1151      0.631708  \n",
       "976       0.623541  \n",
       "3565      0.620138  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a returning user (hybrid)\n",
    "hybrid_recommendation(df, collab_model, user_id='8', user_query=\"The Hobbit\", top_n=10, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c1daf-d973-4c47-a33d-089c747aebf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
